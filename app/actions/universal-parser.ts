'use server';

import { createClient } from '@/utils/supabase/server';
import crypto from 'crypto';
import type { Database } from '@/types/supabase';

// ============================================================================
// UNIVERSAL META-PROMPT (SYSTEM) - PURE COPY FROM parse-pdf-universal.js
// ============================================================================

const SYSTEM_PROMPT = `
–¢—ã ‚Äî —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π AI-–ø–∞—Ä—Å–µ—Ä –Ω–æ—Ä–º–∞—Ç–∏–≤–Ω—ã—Ö –∏ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤.

–¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äî –∏–∑–≤–ª–µ–∫–∞—Ç—å RAW-–§–†–ê–ì–ú–ï–ù–¢–´ –ù–û–†–ú (RawNormFragments),
–∞ –Ω–µ —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å –≥–æ—Ç–æ–≤—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è.

–¢—ã –ù–ï:
‚Äî –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ—à—å –Ω–æ—Ä–º—ã,
‚Äî –Ω–µ –æ–±—ä–µ–¥–∏–Ω—è–µ—à—å —Ä–∞–∑–Ω—ã–µ –ø—É–Ω–∫—Ç—ã,
‚Äî –Ω–µ —É–ø—Ä–æ—â–∞–µ—à—å —Ç–µ–∫—Å—Ç,
‚Äî –Ω–µ –¥–µ–ª–∞–µ—à—å –≤—ã–≤–æ–¥–æ–≤.

–¢—ã –¢–û–õ–¨–ö–û:
‚Äî –Ω–∞—Ö–æ–¥–∏—à—å –Ω–æ—Ä–º–∞—Ç–∏–≤–Ω–æ –∑–Ω–∞—á–∏–º—ã–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã –Ω–∞ –†–£–°–°–ö–û–ú –Ø–ó–´–ö–ï,
‚Äî —Å–æ—Ö—Ä–∞–Ω—è–µ—à—å —Ç–æ—á–Ω—É—é —Ü–∏—Ç–∞—Ç—É (—Ç–æ–ª—å–∫–æ –Ω–∞ —Ä—É—Å—Å–∫–æ–º),
‚Äî —Ñ–∏–∫—Å–∏—Ä—É–µ—à—å —É—Å–ª–æ–≤–∏—è, –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –∏ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã,
‚Äî —Å–æ—Ö—Ä–∞–Ω—è–µ—à—å –ø—Ä–∏–≤—è–∑–∫—É –∫ –∏—Å—Ç–æ—á–Ω–∏–∫—É.

üö® –í–ê–ñ–ù–û–ï –ü–†–ê–í–ò–õ–û –Ø–ó–´–ö–ê:
–î–æ–∫—É–º–µ–Ω—Ç –º–æ–∂–µ—Ç —Å–æ–¥–µ—Ä–∂–∞—Ç—å —Ç–µ–∫—Å—Ç –Ω–∞ –¥–≤—É—Ö —è–∑—ã–∫–∞—Ö (KZ/RU).
–¢–´ –î–û–õ–ñ–ï–ù –ò–ì–ù–û–†–ò–†–û–í–ê–¢–¨ –í–ï–°–¨ –¢–ï–ö–°–¢ –ù–ê –ö–ê–ó–ê–•–°–ö–û–ú –Ø–ó–´–ö–ï.
–ò–ó–í–õ–ï–ö–ê–ô –¢–û–õ–¨–ö–û –¢–ï–ö–°–¢ –ù–ê –†–£–°–°–ö–û–ú –Ø–ó–´–ö–ï.
–ï—Å–ª–∏ —Ñ—Ä–∞–≥–º–µ–Ω—Ç (–∏–ª–∏ –∫–æ–ª–æ–Ω–∫–∞ —Ç–∞–±–ª–∏—Ü—ã) –Ω–∞ –∫–∞–∑–∞—Ö—Å–∫–æ–º ‚Äî –ü–†–û–ü–£–°–ö–ê–ô –ï–ì–û.
`;

const EXTRACTION_CRITERIA = `
## –ö–†–ò–¢–ï–†–ò–ò –ò–ó–í–õ–ï–ß–ï–ù–ò–Ø –§–†–ê–ì–ú–ï–ù–¢–û–í

### 1Ô∏è‚É£ –ú–û–î–ê–õ–¨–ù–û–°–¢–¨ (—è–≤–Ω–∞—è –∏–ª–∏ —Å–∫—Ä—ã—Ç–∞—è)
–ò–∑–≤–ª–µ–∫–∞–π —Ñ—Ä–∞–≥–º–µ–Ω—Ç, –µ—Å–ª–∏ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ:
* –¥–æ–ª–∂–µ–Ω / –¥–æ–ª–∂–Ω–∞ / –¥–æ–ª–∂–Ω—ã / –¥–æ–ª–∂–Ω–æ
* –Ω–µ –¥–æ–ø—É—Å–∫–∞–µ—Ç—Å—è / –∑–∞–ø—Ä–µ—â–∞–µ—Ç—Å—è
* —Å–ª–µ–¥—É–µ—Ç / —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è  
* –¥–æ–ø—É—Å–∫–∞–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ
* –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ / —Ç—Ä–µ–±—É–µ—Ç—Å—è
* –ø–æ–¥–ª–µ–∂–∏—Ç / –æ–±—è–∑–∞–Ω

### 2Ô∏è‚É£ –£–°–õ–û–í–ò–Ø –ü–†–ò–ú–ï–ù–ï–ù–ò–Ø
–ò–∑–≤–ª–µ–∫–∞–π —Ñ—Ä–∞–≥–º–µ–Ω—Ç, –µ—Å–ª–∏ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É–µ—Ç:
* –ø—Ä–∏ / –≤ —Å–ª—É—á–∞–µ / –µ—Å–ª–∏
* –≤ –ø–æ–º–µ—â–µ–Ω–∏—è—Ö / –Ω–∞ –æ–±—ä–µ–∫—Ç–∞—Ö
* –ø—Ä–∏ –Ω–∞–ª–∏—á–∏–∏ / –ø—Ä–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–∏
* –¥–ª—è / –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç

### 3Ô∏è‚É£ –ü–ê–†–ê–ú–ï–¢–†–´ –ò –ù–û–†–ú–ê–¢–ò–í–´
–ò–∑–≤–ª–µ–∫–∞–π —Ñ—Ä–∞–≥–º–µ–Ω—Ç, –µ—Å–ª–∏ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É–µ—Ç:
* —á–∏—Å–ª–æ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
* –µ–¥–∏–Ω–∏—Ü—ã –∏–∑–º–µ—Ä–µ–Ω–∏—è
* –Ω–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–µ –ø—Ä–µ–¥–µ–ª—ã
* —Ç–∞–±–ª–∏—Ü—ã –Ω–æ—Ä–º–∞—Ç–∏–≤–æ–≤
* —Å—Å—ã–ª–∫–∏ –Ω–∞ —Ä–∞—Å—á—ë—Ç

### 4Ô∏è‚É£ –°–¢–†–£–ö–¢–£–†–ù–´–ï –§–†–ê–ì–ú–ï–ù–¢–´
–ò–∑–≤–ª–µ–∫–∞–π:
* –ø—Ä–∏–º–µ—á–∞–Ω–∏—è
* —Ç–∞–±–ª–∏—Ü—ã
* —Å–Ω–æ—Å–∫–∏
* –ø–æ–¥–ø—É–Ω–∫—Ç—ã
`;

const OUTPUT_FORMAT = `
## –§–û–†–ú–ê–¢ –í–´–•–û–î–ù–´–• –î–ê–ù–ù–´–•

–í–µ—Ä–Ω–∏ –¢–û–õ–¨–ö–û –í–ê–õ–ò–î–ù–´–ô JSON –º–∞—Å—Å–∏–≤ –æ–±—ä–µ–∫—Ç–æ–≤. –ö–∞–∂–¥—ã–π –æ–±—ä–µ–∫—Ç - –æ—Ç–¥–µ–ª—å–Ω—ã–π —Ñ—Ä–∞–≥–º–µ–Ω—Ç:

[
  {
    "source_section": "—Ä–∞–∑–¥–µ–ª / –≥–ª–∞–≤–∞",
    "source_clause": "–ø—É–Ω–∫—Ç / –ø–æ–¥–ø—É–Ω–∫—Ç",
    "raw_text": "–¢–û–ß–ù–ê–Ø —Ü–∏—Ç–∞—Ç–∞ –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π",
    "detected_modality": "–¥–æ–ª–∂–µ–Ω | –Ω–µ –¥–æ–ø—É—Å–∫–∞–µ—Ç—Å—è | —Å–ª–µ–¥—É–µ—Ç | null",
    "detected_conditions": ["—É—Å–ª–æ–≤–∏–µ 1", "—É—Å–ª–æ–≤–∏–µ 2"],
    "detected_parameters": [
      {
        "value": "—á–∏—Å–ª–æ",
        "unit": "–µ–¥–∏–Ω–∏—Ü–∞",
        "context": "–∫–æ–Ω—Ç–µ–∫—Å—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä–∞"
      }
    ],
    "predicted_requirement_type": "constructive | functional | parameterized | operational | prohibitive | conditional | base | undefined",
    "confidence_score": 0.95
  }
]

–°–¢–†–û–ì–ò–ï –ü–†–ê–í–ò–õ–ê:
‚ùå –ù–ï —Å–æ–∑–¥–∞–≤–∞–π –Ω–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è
‚ùå –ù–ï –ø–µ—Ä–µ–ø–∏—Å—ã–≤–∞–π —Ç–µ–∫—Å—Ç
‚ùå –ù–ï –æ–±—ä–µ–¥–∏–Ω—è–π —Ä–∞–∑–Ω—ã–µ –Ω–æ—Ä–º—ã
‚ùå –ù–ï –¥–µ–ª–∞–π –ª–æ–≥–∏—á–µ—Å–∫–∏—Ö –≤—ã–≤–æ–¥–æ–≤
‚ùå –ù–ï —É–±–∏—Ä–∞–π —É—Å–ª–æ–≤–∏—è –∏ –∏—Å–∫–ª—é—á–µ–Ω–∏—è

–ï—Å–ª–∏ —Ñ—Ä–∞–≥–º–µ–Ω—Ç —Å–æ–º–Ω–∏—Ç–µ–ª—å–Ω—ã–π ‚Äî –∏–∑–≤–ª–µ–∫–∞–π —Å –Ω–∏–∑–∫–∏–º confidence_score (< 0.7).
`;

// ============================================================================
// MONOLITHIC PARSING FUNCTION (SERVER ACTION)
// ============================================================================

export async function runFullParsing(normSourceId: string) {
    console.log(`\nüîç UNIVERSAL PARSER: Starting full process for ${normSourceId}`);
    const supabase = createClientWithServiceRole();
    const apiKey = process.env.OPENAI_API_KEY;

    try {
        if (!apiKey) throw new Error('OPENAI_API_KEY is missing');

        // 1. Get Norm & File URL
        const { data: norm, error: normError } = await supabase
            .from('norm_sources')
            .select('*')
            .eq('id', normSourceId)
            .single();

        if (normError || !norm) throw new Error('Norm not found');

        await supabase.from('norm_sources').update({
            status: 'PARSING',
            parsing_details: '–ü–æ–∏—Å–∫ —Ñ–∞–π–ª–∞...',
            updatedAt: new Date().toISOString()
        }).eq('id', normSourceId);

        const { data: files } = await supabase
            .from('norm_files')
            .select('storageUrl')
            .eq('normSourceId', normSourceId)
            .limit(1);

        if (!files || !files.length) throw new Error('File record not found');
        const storageUrl = files[0].storageUrl;

        // 2. Download File (HTTP or Local or Storage)
        let pdfBuffer: Buffer;
        await supabase.from('norm_sources').update({ parsing_details: '–°–∫–∞—á–∏–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞...' }).eq('id', normSourceId);

        if (storageUrl.startsWith('http')) {
            // Public/External URL
            const res = await fetch(storageUrl);
            const arrayBuffer = await res.arrayBuffer();
            pdfBuffer = Buffer.from(arrayBuffer);
        } else if (storageUrl.includes('norm-docs/')) {
            // Internal Storage Path
            const path = storageUrl.split('norm-docs/')[1];
            const { data, error } = await supabase.storage.from('norm-docs').download(path);
            if (error) throw error;
            pdfBuffer = Buffer.from(await data.arrayBuffer());
        } else {
            // Local File Path (Dev Mode)
            const fs = require('fs');
            // Try explicit path first, then relative to cwd
            if (fs.existsSync(storageUrl)) {
                pdfBuffer = fs.readFileSync(storageUrl);
            } else {
                throw new Error(`Local file not found: ${storageUrl}`);
            }
        }

        // 3. Extract Text via PDF-Parse
        await supabase.from('norm_sources').update({ parsing_details: '–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ (PDF)...' }).eq('id', normSourceId);
        const pdf = require('pdf-parse');
        const pdfData = await pdf(pdfBuffer);
        const fullText = pdfData.text;

        if (!fullText || fullText.length < 50) throw new Error('–¢–µ–∫—Å—Ç PDF –ø—É—Å—Ç –∏–ª–∏ –Ω–µ –∏–∑–≤–ª–µ—á–µ–Ω');
        console.log(`   ‚úÖ Extracted ${fullText.length} chars`);

        // 4. Chunking
        const CHUNK_SIZE = 12000;
        const chunks = [];
        for (let i = 0; i < fullText.length; i += CHUNK_SIZE) {
            chunks.push(fullText.substring(i, i + CHUNK_SIZE));
        }
        console.log(`   üì¶ Split into ${chunks.length} chunks`);

        // 5. AI Loop (Parallel Batches of 3)
        const BATCH_SIZE = 3;
        let allFragments: any[] = [];
        let fragmentCounter = 1;

        for (let i = 0; i < chunks.length; i += BATCH_SIZE) {
            const currentBatch = chunks.slice(i, i + BATCH_SIZE);
            const batchIndex = Math.floor(i / BATCH_SIZE) + 1;
            const totalBatches = Math.ceil(chunks.length / BATCH_SIZE);

            const msg = `–û–±—Ä–∞–±–æ—Ç–∫–∞ AI: –±–∞—Ç—á ${batchIndex}/${totalBatches}`;
            console.log(`   [Batch ${batchIndex}] Processing...`);
            await supabase.from('norm_sources').update({ parsing_details: msg }).eq('id', normSourceId);

            const batchPromises = currentBatch.map(async (chunk, idx) => {
                const chunkNum = i + idx + 1;
                try {
                    const response = await fetch('https://api.openai.com/v1/chat/completions', {
                        method: 'POST',
                        headers: { 'Content-Type': 'application/json', 'Authorization': `Bearer ${apiKey}` },
                        body: JSON.stringify({
                            model: "gpt-4o-mini",
                            messages: [
                                { role: "system", content: SYSTEM_PROMPT + '\n' + EXTRACTION_CRITERIA + '\n' + OUTPUT_FORMAT },
                                { role: "user", content: `## –¢–ï–ö–°–¢ (–ë–õ–û–ö ${chunkNum})\n${chunk}\n\nüö® –ü–†–ê–í–ò–õ–û: –ò–∑–≤–ª–µ–∫–∞–π –¢–û–õ–¨–ö–û —Ä—É—Å—Å–∫–∏–π —Ç–µ–∫—Å—Ç.\n–í–µ—Ä–Ω–∏ JSON –º–∞—Å—Å–∏–≤.` }
                            ], // Using slightly simplified user prompt but FULL system prompt
                            response_format: { type: "json_object" },
                            temperature: 0.1
                        })
                    });

                    if (!response.ok) return [];
                    const result = await response.json();
                    const content = result.choices[0]?.message?.content;
                    if (!content) return [];

                    const data = JSON.parse(content);
                    // Robust extraction logic from my last fix
                    if (Array.isArray(data)) return data;
                    if (data.fragments && Array.isArray(data.fragments)) return data.fragments;
                    if (data.raw_norm_fragments && Array.isArray(data.raw_norm_fragments)) return data.raw_norm_fragments;
                    return [];

                } catch (e) {
                    console.error(`Error in chunk ${chunkNum}`, e);
                    return [];
                }
            });

            const results = await Promise.all(batchPromises);
            results.flat().forEach(frag => {
                frag.fragment_id = `${normSourceId.substring(0, 8)}-${String(fragmentCounter).padStart(5, '0')}`;
                allFragments.push(frag);
                fragmentCounter++;
            });
        }

        // 6. Save to DB
        console.log(`   üíæ Saving ${allFragments.length} fragments...`);
        if (allFragments.length > 0) {
            const records = allFragments.map((f: any) => ({
                id: crypto.randomUUID(),
                normSourceId,
                fragmentId: f.fragment_id,
                sourceSection: f.source_section || null,
                sourceClause: f.source_clause || null,
                rawText: f.raw_text,
                detectedModality: f.detected_modality || null,
                detectedConditions: f.detected_conditions || [],
                detectedParameters: f.detected_parameters || null,
                predictedRequirementType: f.predicted_requirement_type || null,
                confidenceScore: f.confidence_score || 0.8,
                status: 'PENDING',
                createdAt: new Date().toISOString(),
                updatedAt: new Date().toISOString()
            }));

            // Batch insert
            const DB_BATCH = 50;
            for (let i = 0; i < records.length; i += DB_BATCH) {
                const batch = records.slice(i, i + DB_BATCH);
                await supabase.from('raw_norm_fragments').insert(batch);
            }
        }

        // 7. Finish
        await supabase.from('norm_sources').update({
            status: 'DRAFT',
            parsing_details: null,
            updatedAt: new Date().toISOString()
        }).eq('id', normSourceId);

        return { success: true, count: allFragments.length };

    } catch (err: any) {
        console.error('CRITICAL PARSING ERROR:', err);
        await supabase.from('norm_sources').update({
            status: 'DRAFT',
            parsing_details: `–û—à–∏–±–∫–∞: ${err.message}`,
            updatedAt: new Date().toISOString()
        }).eq('id', normSourceId);
        return { success: false, error: err.message };
    }
}

// Helpers retained
function createClientWithServiceRole() {
    const { createClient: createSupabaseClient } = require('@supabase/supabase-js');
    return createSupabaseClient(
        process.env.NEXT_PUBLIC_SUPABASE_URL!,
        process.env.SUPABASE_SERVICE_ROLE_KEY!,
        { auth: { autoRefreshToken: false, persistSession: false } }
    );
}

// Stub for exported functions to keep imports working temporarily if needed (deprecated)
export async function getSignedReadUrl() { return { success: false } }
export async function getSignedUploadUrl() { return { success: false } }
export async function notifyTextReady() { return { success: false } }
export async function extractNormText() { return { success: false } }
export async function processNormBatch() { return { success: false } }
