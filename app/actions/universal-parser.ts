'use server';

import { createClient } from '@/utils/supabase/server';
import crypto from 'crypto';

/**
 * STEP -1: Generate Signed URL for Client-Side Extraction
 */
export async function getSignedReadUrl(normSourceId: string) {
    const supabase = createClient();
    try {
        console.log('[SERVER] getSignedReadUrl called for:', normSourceId);

        // 1. Check strict permissions via standard client (RLS)
        const { data: files, error: filesError } = await supabase
            .from('norm_files')
            .select('storageUrl')
            .eq('normSourceId', normSourceId)
            .limit(1);

        if (filesError) {
            console.error('[SERVER] Database error:', filesError);
            throw new Error(`Database error: ${filesError.message}`);
        }

        if (!files || files.length === 0) {
            console.error('[SERVER] No files found for normSourceId:', normSourceId);
            throw new Error('PDF-—Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω');
        }

        const storageUrl = files[0].storageUrl;
        console.log('[SERVER] Storage URL:', storageUrl);

        // 2. Check if it's already a PUBLIC URL
        if (storageUrl.includes('/public/')) {
            console.log('[SERVER] Public URL detected, returning as-is');
            return { success: true, url: storageUrl };
        }

        // 3. Extract path
        const pathMatch = storageUrl.match(/norm-docs\/(.+)/);
        if (!pathMatch) {
            console.log('[SERVER] Could not extract path from URL, returning as-is');
            return { success: true, url: storageUrl };
        }

        const filePath = pathMatch[1];
        console.log('[SERVER] Creating signed URL for path:', filePath);

        // 4. Use Service Role client for signing (Bypass Storage RLS)
        // This is safe because we verified access to the record in step 1
        const adminClient = createClientWithServiceRole();

        const { data, error } = await adminClient.storage
            .from('norm-docs')
            .createSignedUrl(filePath, 600); // 10 mins

        if (error) {
            console.error('[SERVER] Signed URL error:', error);
            // Fallback: return authorized URL if signing fails (might be public but not detected)
            if (error.message.includes('Object not found')) {
                console.log('[SERVER] Object not found via API, trying direct public URL check...');
                // If we can't sign it, maybe we can just read it? 
                // But for now let's throw detailed error
            }
            throw error;
        }

        console.log('[SERVER] Signed URL created successfully');
        return { success: true, url: data.signedUrl };
    } catch (err: any) {
        console.error('[SERVER] Exception in getSignedReadUrl:', err);
        return { success: false, error: err.message || 'Unknown error' };
    }
}

// Helper for admin client
function createClientWithServiceRole() {
    const { createClient: createSupabaseClient } = require('@supabase/supabase-js');
    return createSupabaseClient(
        process.env.NEXT_PUBLIC_SUPABASE_URL!,
        process.env.SUPABASE_SERVICE_ROLE_KEY!,
        {
            auth: {
                autoRefreshToken: false,
                persistSession: false
            }
        }
    );
}

/**
 * STEP 2.5: Generate Signed URL for Uploading Text (Bypass RLS)
 */
export async function getSignedUploadUrl(normSourceId: string) {
    try {
        console.log('[SERVER] getSignedUploadUrl called for:', normSourceId);
        const adminClient = createClientWithServiceRole();
        const path = `temp-text/${normSourceId}.txt`;

        // Always try to remove the file first to avoid "Resource already exists" error on retries
        await adminClient.storage.from('norm-docs').remove([path]);

        const { data, error } = await adminClient.storage
            .from('norm-docs')
            .createSignedUploadUrl(path);

        if (error) {
            console.error('[SERVER] Failed to create signed upload URL:', error);
            throw error;
        }

        console.log('[SERVER] Signed upload URL created');
        return { success: true, data: data };
    } catch (err: any) {
        console.error('[SERVER] Exception in getSignedUploadUrl:', err);
        return { success: false, error: err.message };
    }
}

/**
 * STEP 0: notify server that text is ready in storage
 */
export async function notifyTextReady(normSourceId: string, charCount: number) {
    const supabase = createClient();
    try {
        const CHUNK_SIZE = 12000;
        const chunkCount = Math.ceil(charCount / CHUNK_SIZE);

        await supabase.from('norm_sources').update({
            parsing_details: `–¢–µ–∫—Å—Ç –≥–æ—Ç–æ–≤ (–≤ –æ–±–ª–∞–∫–µ). –í—Å–µ–≥–æ –±–ª–æ–∫–æ–≤: ${chunkCount}`,
            updatedAt: new Date().toISOString()
        }).eq('id', normSourceId);

        return { success: true, chunkCount };
    } catch (err: any) {
        return { success: false, error: err.message };
    }
}

/**
 * STEP 1: Extract Text and Save to Storage
 */
export async function extractNormText(normSourceId: string) {
    const supabase = createClient();
    try {
        console.log(`[EXTRACT] Starting extraction for ${normSourceId}`);

        // Update status
        await supabase.from('norm_sources').update({
            status: 'PARSING',
            parsing_details: '–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏–∑ PDF...',
            updatedAt: new Date().toISOString()
        }).eq('id', normSourceId);

        return {
            success: false,
            error: 'Server-side extraction is deprecated. Use client-side extraction instead.'
        };

    } catch (err: any) {
        console.error('[EXTRACT] Error:', err);
        await supabase.from('norm_sources').update({
            status: 'DRAFT',
            parsing_details: `–û—à–∏–±–∫–∞ —ç–∫—Å—Ç—Ä–∞–∫—Ü–∏–∏: ${err.message}`,
            updatedAt: new Date().toISOString()
        }).eq('id', normSourceId);
        return { success: false, error: err.message };
    }
}

/**
 * STEP 2: Process a specific batch via AI
 */
export async function processNormBatch(normSourceId: string, batchIndex: number, totalChunks: number, chunkText: string) {
    const supabase = createClient();
    try {
        if (!chunkText) {
            console.log(`[BATCH ${batchIndex}] Empty chunk text`);
            return { success: true, fragments: [] };
        }

        console.log(`[BATCH ${batchIndex}] Processing chunk length: ${chunkText.length}`);

        // Update progress
        await supabase.from('norm_sources').update({
            parsing_details: `–û–±—Ä–∞–±–æ—Ç–∫–∞ –±–ª–æ–∫–∞ ${batchIndex + 1} –∏–∑ ${totalChunks}...`,
            updatedAt: new Date().toISOString()
        }).eq('id', normSourceId);

        // AI Extraction Logic
        const apiKey = process.env.OPENAI_API_KEY;
        if (!apiKey) throw new Error('OPENAI_API_KEY not configured');

        // ============================================================================
        // UNIVERSAL META-PROMPT (SYSTEM) - RESTORED FROM parse-pdf-universal.js
        // ============================================================================
        const SYSTEM_PROMPT = `
–¢—ã ‚Äî —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π AI-–ø–∞—Ä—Å–µ—Ä –Ω–æ—Ä–º–∞—Ç–∏–≤–Ω—ã—Ö –∏ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤.

–¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äî –∏–∑–≤–ª–µ–∫–∞—Ç—å RAW-–§–†–ê–ì–ú–ï–ù–¢–´ –ù–û–†–ú (RawNormFragments),
–∞ –Ω–µ —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å –≥–æ—Ç–æ–≤—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è.

–¢—ã –ù–ï:
‚Äî –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ—à—å –Ω–æ—Ä–º—ã,
‚Äî –Ω–µ –æ–±—ä–µ–¥–∏–Ω—è–µ—à—å —Ä–∞–∑–Ω—ã–µ –ø—É–Ω–∫—Ç—ã,
‚Äî –Ω–µ —É–ø—Ä–æ—â–∞–µ—à—å —Ç–µ–∫—Å—Ç,
‚Äî –Ω–µ –¥–µ–ª–∞–µ—à—å –≤—ã–≤–æ–¥–æ–≤.

–¢—ã –¢–û–õ–¨–ö–û:
‚Äî –Ω–∞—Ö–æ–¥–∏—à—å –Ω–æ—Ä–º–∞—Ç–∏–≤–Ω–æ –∑–Ω–∞—á–∏–º—ã–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã –Ω–∞ –†–£–°–°–ö–û–ú –Ø–ó–´–ö–ï,
‚Äî —Å–æ—Ö—Ä–∞–Ω—è–µ—à—å —Ç–æ—á–Ω—É—é —Ü–∏—Ç–∞—Ç—É (—Ç–æ–ª—å–∫–æ –Ω–∞ —Ä—É—Å—Å–∫–æ–º),
‚Äî —Ñ–∏–∫—Å–∏—Ä—É–µ—à—å —É—Å–ª–æ–≤–∏—è, –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –∏ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã,
‚Äî —Å–æ—Ö—Ä–∞–Ω—è–µ—à—å –ø—Ä–∏–≤—è–∑–∫—É –∫ –∏—Å—Ç–æ—á–Ω–∏–∫—É.

üö® –í–ê–ñ–ù–û–ï –ü–†–ê–í–ò–õ–û –Ø–ó–´–ö–ê:
–î–æ–∫—É–º–µ–Ω—Ç –º–æ–∂–µ—Ç —Å–æ–¥–µ—Ä–∂–∞—Ç—å —Ç–µ–∫—Å—Ç –Ω–∞ –¥–≤—É—Ö —è–∑—ã–∫–∞—Ö (KZ/RU).
–¢–´ –î–û–õ–ñ–ï–ù –ò–ì–ù–û–†–ò–†–û–í–ê–¢–¨ –í–ï–°–¨ –¢–ï–ö–°–¢ –ù–ê –ö–ê–ó–ê–•–°–ö–û–ú –Ø–ó–´–ö–ï.
–ò–ó–í–õ–ï–ö–ê–ô –¢–û–õ–¨–ö–û –¢–ï–ö–°–¢ –ù–ê –†–£–°–°–ö–û–ú –Ø–ó–´–ö–ï.
–ï—Å–ª–∏ —Ñ—Ä–∞–≥–º–µ–Ω—Ç (–∏–ª–∏ –∫–æ–ª–æ–Ω–∫–∞ —Ç–∞–±–ª–∏—Ü—ã) –Ω–∞ –∫–∞–∑–∞—Ö—Å–∫–æ–º ‚Äî –ü–†–û–ü–£–°–ö–ê–ô –ï–ì–û.
`;

        const EXTRACTION_CRITERIA = `
## –ö–†–ò–¢–ï–†–ò–ò –ò–ó–í–õ–ï–ß–ï–ù–ò–Ø –§–†–ê–ì–ú–ï–ù–¢–û–í

### 1Ô∏è‚É£ –ú–û–î–ê–õ–¨–ù–û–°–¢–¨ (—è–≤–Ω–∞—è –∏–ª–∏ —Å–∫—Ä—ã—Ç–∞—è)
–ò–∑–≤–ª–µ–∫–∞–π —Ñ—Ä–∞–≥–º–µ–Ω—Ç, –µ—Å–ª–∏ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ:
* –¥–æ–ª–∂–µ–Ω / –¥–æ–ª–∂–Ω–∞ / –¥–æ–ª–∂–Ω—ã / –¥–æ–ª–∂–Ω–æ
* –Ω–µ –¥–æ–ø—É—Å–∫–∞–µ—Ç—Å—è / –∑–∞–ø—Ä–µ—â–∞–µ—Ç—Å—è
* —Å–ª–µ–¥—É–µ—Ç / —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è  
* –¥–æ–ø—É—Å–∫–∞–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ
* –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ / —Ç—Ä–µ–±—É–µ—Ç—Å—è
* –ø–æ–¥–ª–µ–∂–∏—Ç / –æ–±—è–∑–∞–Ω

### 2Ô∏è‚É£ –£–°–õ–û–í–ò–Ø –ü–†–ò–ú–ï–ù–ï–ù–ò–Ø
–ò–∑–≤–ª–µ–∫–∞–π —Ñ—Ä–∞–≥–º–µ–Ω—Ç, –µ—Å–ª–∏ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É–µ—Ç:
* –ø—Ä–∏ / –≤ —Å–ª—É—á–∞–µ / –µ—Å–ª–∏
* –≤ –ø–æ–º–µ—â–µ–Ω–∏—è—Ö / –Ω–∞ –æ–±—ä–µ–∫—Ç–∞—Ö
* –ø—Ä–∏ –Ω–∞–ª–∏—á–∏–∏ / –ø—Ä–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–∏
* –¥–ª—è / –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç

### 3Ô∏è‚É£ –ü–ê–†–ê–ú–ï–¢–†–´ –ò –ù–û–†–ú–ê–¢–ò–í–´
–ò–∑–≤–ª–µ–∫–∞–π —Ñ—Ä–∞–≥–º–µ–Ω—Ç, –µ—Å–ª–∏ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É–µ—Ç:
* —á–∏—Å–ª–æ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
* –µ–¥–∏–Ω–∏—Ü—ã –∏–∑–º–µ—Ä–µ–Ω–∏—è
* –Ω–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–µ –ø—Ä–µ–¥–µ–ª—ã
* —Ç–∞–±–ª–∏—Ü—ã –Ω–æ—Ä–º–∞—Ç–∏–≤–æ–≤
* —Å—Å—ã–ª–∫–∏ –Ω–∞ —Ä–∞—Å—á—ë—Ç

### 4Ô∏è‚É£ –°–¢–†–£–ö–¢–£–†–ù–´–ï –§–†–ê–ì–ú–ï–ù–¢–´
–ò–∑–≤–ª–µ–∫–∞–π:
* –ø—Ä–∏–º–µ—á–∞–Ω–∏—è
* —Ç–∞–±–ª–∏—Ü—ã
* —Å–Ω–æ—Å–∫–∏
* –ø–æ–¥–ø—É–Ω–∫—Ç—ã
`;

        const OUTPUT_FORMAT = `
## –§–û–†–ú–ê–¢ –í–´–•–û–î–ù–´–• –î–ê–ù–ù–´–•

–í–µ—Ä–Ω–∏ –¢–û–õ–¨–ö–û –í–ê–õ–ò–î–ù–´–ô JSON –º–∞—Å—Å–∏–≤ –æ–±—ä–µ–∫—Ç–æ–≤. –ö–∞–∂–¥—ã–π –æ–±—ä–µ–∫—Ç - –æ—Ç–¥–µ–ª—å–Ω—ã–π —Ñ—Ä–∞–≥–º–µ–Ω—Ç:

[
  {
    "source_section": "—Ä–∞–∑–¥–µ–ª / –≥–ª–∞–≤–∞",
    "source_clause": "–ø—É–Ω–∫—Ç / –ø–æ–¥–ø—É–Ω–∫—Ç",
    "raw_text": "–¢–û–ß–ù–ê–Ø —Ü–∏—Ç–∞—Ç–∞ –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π",
    "detected_modality": "–¥–æ–ª–∂–µ–Ω | –Ω–µ –¥–æ–ø—É—Å–∫–∞–µ—Ç—Å—è | —Å–ª–µ–¥—É–µ—Ç | null",
    "detected_conditions": ["—É—Å–ª–æ–≤–∏–µ 1", "—É—Å–ª–æ–≤–∏–µ 2"],
    "detected_parameters": [
      {
        "value": "—á–∏—Å–ª–æ",
        "unit": "–µ–¥–∏–Ω–∏—Ü–∞",
        "context": "–∫–æ–Ω—Ç–µ–∫—Å—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä–∞"
      }
    ],
    "predicted_requirement_type": "constructive | functional | parameterized | operational | prohibitive | conditional | base | undefined",
    "confidence_score": 0.95
  }
]

–°–¢–†–û–ì–ò–ï –ü–†–ê–í–ò–õ–ê:
‚ùå –ù–ï —Å–æ–∑–¥–∞–≤–∞–π –Ω–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è
‚ùå –ù–ï –ø–µ—Ä–µ–ø–∏—Å—ã–≤–∞–π —Ç–µ–∫—Å—Ç
‚ùå –ù–ï –æ–±—ä–µ–¥–∏–Ω—è–π —Ä–∞–∑–Ω—ã–µ –Ω–æ—Ä–º—ã
‚ùå –ù–ï –¥–µ–ª–∞–π –ª–æ–≥–∏—á–µ—Å–∫–∏—Ö –≤—ã–≤–æ–¥–æ–≤
‚ùå –ù–ï —É–±–∏—Ä–∞–π —É—Å–ª–æ–≤–∏—è –∏ –∏—Å–∫–ª—é—á–µ–Ω–∏—è

–ï—Å–ª–∏ —Ñ—Ä–∞–≥–º–µ–Ω—Ç —Å–æ–º–Ω–∏—Ç–µ–ª—å–Ω—ã–π ‚Äî –∏–∑–≤–ª–µ–∫–∞–π —Å –Ω–∏–∑–∫–∏–º confidence_score (< 0.7).
`;

        // Reuse prompts from parse-pdf-universal.js logic
        const response = await fetch('https://api.openai.com/v1/chat/completions', {
            method: 'POST',
            headers: { 'Content-Type': 'application/json', 'Authorization': `Bearer ${apiKey}` },
            body: JSON.stringify({
                model: "gpt-4o-mini",
                messages: [
                    { role: "system", content: SYSTEM_PROMPT + '\n' + EXTRACTION_CRITERIA + '\n' + OUTPUT_FORMAT },
                    { role: "user", content: `## –¢–ï–ö–°–¢ (–ë–õ–û–ö ${batchIndex + 1})\n${chunkText}\n\nüö® –ü–†–ê–í–ò–õ–û: –ò–∑–≤–ª–µ–∫–∞–π –¢–û–õ–¨–ö–û —Ä—É—Å—Å–∫–∏–π —Ç–µ–∫—Å—Ç. –ï—Å–ª–∏ –≤—Å—ë –Ω–∞ –∫–∞–∑–∞—Ö—Å–∫–æ–º ‚Äî –≤–µ—Ä–Ω–∏ –ø—É—Å—Ç–æ–π –º–∞—Å—Å–∏–≤.\n–í–µ—Ä–Ω–∏ –¢–û–õ–¨–ö–û –≤–∞–ª–∏–¥–Ω—ã–π JSON: {"raw_norm_fragments": [...]}` }
                ],
                response_format: { type: "json_object" },
                temperature: 0.1
            })
        });

        if (!response.ok) throw new Error(`AI API error: ${response.status}`);
        const result = await response.json();
        console.log(`[BATCH ${batchIndex}] AI Raw Response:`, result.choices[0]?.message?.content?.substring(0, 200));

        const data = JSON.parse(result.choices[0]?.message?.content || '{"fragments": []}');
        const fragments = data.fragments || data.raw_norm_fragments || [];

        // 4. Save to DB
        if (fragments.length > 0) {
            const records = fragments.map((f: any) => ({
                id: crypto.randomUUID(),
                normSourceId,
                sourceSection: f.source_section || null,
                sourceClause: f.source_clause || null,
                rawText: f.raw_text,
                detectedModality: f.detected_modality || null,
                detectedConditions: f.detected_conditions || [],
                detectedParameters: f.detected_parameters || null,
                predictedRequirementType: f.predicted_requirement_type || null,
                confidenceScore: f.confidence_score || 0.8,
                status: 'PENDING'
            }));

            await supabase.from('raw_norm_fragments').insert(records);
        }

        // Final check
        if (batchIndex + 1 === totalChunks) {
            await supabase.from('norm_sources').update({
                status: 'DRAFT',
                parsing_details: null,
                updatedAt: new Date().toISOString()
            }).eq('id', normSourceId);

            // Cleanup is handled by background job or ignored (it's temp)
        }

        return { success: true, count: fragments.length };

    } catch (err: any) {
        console.error(`[BATCH ${batchIndex}] Error:`, err);
        return { success: false, error: err.message };
    }
}

export async function parseNormUniversal(normSourceId: string) {
    // Keep legacy for compatibility but suggest using staged
    return { success: false, message: 'Use staged parsing instead' };
}
